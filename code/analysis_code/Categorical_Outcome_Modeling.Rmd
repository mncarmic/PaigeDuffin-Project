---
title: "Categorical_Outcomes"
author: "Paige Duffin"
date: "11/7/2019"
output: html_document
---

# Exploratory Analysis {.tabset}

## Preparing Workspace

Load necessary packages
```{r}
library(caret) # Classification and Regression Training
library(corrplot)
library(dplyr) # A Grammar of Data Manipulations
library(forcats) # Tools for Working with Categorical Variables (Factors)
library(gdata) # Various R Programming Tools for Data Manipulation
library(ggplot2) # Create Elegant Data Visualizations Using the Grammar of Graphics
library(ggrepel) # Automatically Position Non-Overlapping Text Labels with ‘ggplot2’
library(ggridges) # Ridgeline Plots in ‘ggplot2’
library(ggthemes) # Extra Themes, Scales, and Geoms for ‘ggplot2’
library(gmodels) # Various R Programming Tools for Model Fitting
library(grid) # The Grid Graphics Package
library(gridExtra)
library(knitr) # A General-Purpose Package for Dynamic Report Generation in R
library(lmtest) # Testing Linear Regression Models
library(plyr) # Tools for Splitting, Applying and Combining Data
library(purrr) # Functional Programming Tools
library(readr) # Read Rectangular Text Data
library(rpart)
library(rattle)
library(scales) # Scale Functions for Visualization
library(shiny) # Web Application Framework for R
library(skimr) # Compact and Flexible Summaries of Data
library(stringr) # Simple, Consistent Wrappers for Common String Operations
library(tibble) # Simple Data Frames
library(tidyr) # Easily Tidy Data with ‘spread()’ and ‘gather()’ Functions
library(tidyverse) # Install and Load ‘Tidyverse’ Packages
library(usmap)
library(rworldmap)
library(ggmap)
library(maps)
library(mapdata)
library(cowplot)
library("googleway")
library("ggspatial") 
library("rnaturalearth") 
library("rnaturalearthdata")
theme_set(theme_bw())
library("sf")
library(gridExtra)

world <- ne_countries(scale = "medium", returnclass = "sf") #for mapping
```
Creating dfs of color schemes I may use 
```{r}
state_colors <- c("brown1","lightseagreen","goldenrod1","slateblue")
species_colors <- c("royalblue","salmon","darkmagenta")
pisaster_colors <- c("thistle1","plum","orchid3","darkmagenta")
RMSE_colors <- c("slategray1","steelblue3","thistle2","plum3")
bioreg_colours <- c("brown3","goldenrod1","darkolivegreen4","skyblue3","mediumpurple3","hotpink3")
```

Load cleaned data
```{r}
#clean_data <- readRDS("./data/processed_data/processeddata.rds")
clean_data <- readRDS("../../data/processed_data/processeddata.rds")
skim(clean_data)
```

```{r}
names(clean_data)
```

# Bioregion
```{r}
summary(clean_data$bioregion)
```


```{r}
bioregion_counts <- clean_data %>% mutate(bioregion = recode(bioregion, "AK_2_BritColumb"="AK to \n British \n Columbia","ChannelIsl_South"="Channel \n Islands \n South","SalishSea_WA"="Salish \n Sea, WA","OlyCstWA_2_SanFran"="Olympic \n Coast WA \n to SanFran","SanFran_2_GovtPt"="SanFran to \n Gov't Point","GovtPt_2_Mexico"="Gov't Point \n to Mexico"))
skim(bioregion_counts$bioregion)

bioregion_counts_ordered <- bioregion_counts %>%
  mutate(bioregion = factor(bioregion, levels = c("AK to \n British \n Columbia","Salish \n Sea, WA","Olympic \n Coast WA \n to SanFran","SanFran to \n Gov't Point","Channel \n Islands \n South","Gov't Point \n to Mexico"))) %>%
  arrange(bioregion) 
```

```{r}
bioregion_histogram <- bioregion_counts_ordered %>% ggplot() + geom_bar(aes(bioregion),fill=bioreg_colours) #+  theme(axis.text.x = element_text(angle=25, hjust=1))
bioregion_histogram 
ggsave(filename = "../../results/Categorical_Outcome_Modeling_results/1.bioregion_histogram.png",plot =bioregion_histogram , width = 5, height = 4)
```

Data visualization
#write code that produces plots showing our outcome of interest on the x-axis and each numeric predictor on the y-axis.

```{r}
bioregion_counts_ordered$season_sequence <- as.factor(bioregion_counts_ordered$season_sequence)
numer_data <- bioregion_counts_ordered %>% select_if(is.numeric) 

numer_data$bioregion <- bioregion_counts_ordered$bioregion

numer_data <- numer_data %>% dplyr::select(-size_sort_order)
```

```{r}
numer_data_plot <- numer_data %>% gather(-bioregion, key = "var", value = "value") %>% 
            ggplot() + geom_point(aes(x = bioregion, y=value, col=bioregion)) + theme(axis.text.x = element_blank()) +
            facet_wrap(~ var, scales = "free") + theme_bw() + theme(legend.position = "none", axis.title.x = element_blank()) +  scale_color_manual(values=bioreg_colours)
print(numer_data_plot)
```


```{r}
latitude_bioreg <- numer_data %>% ggplot(aes(x = bioregion, y=latitude, col=bioregion)) + geom_boxplot() + geom_point(size=4,alpha=0.1) + ylab("Latitude") + theme(axis.text.x = element_blank(),axis.title.x=element_blank(),legend.position = "none",axis.title.y=element_text(size=12),axis.text.y=element_text(size=12)) + scale_color_manual(values=bioreg_colours)
#latitude_bioreg

longitude_bioreg <- numer_data %>% ggplot(aes(x = bioregion, y=longitude, col=bioregion)) + geom_boxplot() + geom_point(size=4,alpha=0.1) + ylab("Longitude") +  theme(axis.text.x = element_blank(),axis.title.x=element_blank(),legend.position = "none",axis.title.y=element_text(size=12),axis.text.y=element_text(size=12)) + scale_color_manual(values=bioreg_colours)
#longitude_bioreg


season_chron_bioreg <- numer_data %>% ggplot(aes(x = bioregion, y=marine_common_season, col=bioregion)) + geom_boxplot() + geom_point(size=4,alpha=0.1) + ylab("Season & Year") + theme(axis.text.x = element_blank(),axis.title.x=element_blank(),legend.position = "none",axis.title.y=element_text(size=12),axis.text.y=element_text(size=12)) + scale_color_manual(values=bioreg_colours)
#season_chron_bioreg

year_bioreg <- numer_data %>% ggplot(aes(x = bioregion, y=marine_common_year, col=bioregion)) + geom_boxplot() + geom_point(size=4,alpha=0.1) + ylab("Year") +  theme(axis.text.x = element_blank(),axis.title.x=element_blank(),legend.position = "none",axis.title.y=element_text(size=12),axis.text.y=element_text(size=12)) + scale_color_manual(values=bioreg_colours)
#year_bioreg

site_bioreg <- numer_data %>% ggplot(aes(x = bioregion, y=marine_sort_order, col=bioregion)) + geom_boxplot() + geom_point(size=4,alpha=0.1) + ylab("Sites (Ordered)") +  theme(axis.text.x = element_blank(),axis.title.x=element_blank(),legend.position = "none",axis.title.y=element_text(size=12),axis.text.y=element_text(size=12)) + scale_color_manual(values=bioreg_colours)
#site_bioreg

size_bioreg <- numer_data %>% ggplot(aes(x = bioregion, y=size_bin, col=bioregion)) + geom_boxplot() + geom_point(size=4,alpha=0.1) + ylab("Size Class") +  theme(axis.text.x = element_blank(),axis.title.x=element_blank(),legend.position = "none",axis.title.y=element_text(size=12),axis.text.y=element_text(size=12)) + scale_color_manual(values=bioreg_colours)
#size_bioreg

abundance_bioreg <- numer_data %>% ggplot(aes(x = bioregion, y=log(total), col=bioregion)) + geom_boxplot() + geom_point(size=4,alpha=0.1) + ylab("log(Spp. Abundance)") +  theme(axis.text.x = element_blank(),axis.title.x=element_blank(),legend.position = "none",axis.title.y=element_text(size=12),axis.text.y=element_text(size=12)) + scale_color_manual(values=bioreg_colours)
#abundance_bioreg
```


```{r}
grid.arrange(latitude_bioreg,longitude_bioreg,site_bioreg,nrow=1,top="(A) Spatial Numeric Predictors")
ggsave(filename = "../../results/Categorical_Outcome_Modeling_results/2.spatial_num_pred.png",plot =grid.arrange(latitude_bioreg,longitude_bioreg,site_bioreg,nrow=1,top="(A) Spatial Numeric Predictors")
 , width = 5, height = 4)

grid.arrange(season_chron_bioreg,year_bioreg,nrow=1,top="(B) Temporal Numeric Predictors")
ggsave(filename = "../../results/Categorical_Outcome_Modeling_results/3.temporal_num_pred.png",plot =grid.arrange(season_chron_bioreg,year_bioreg,nrow=1,top="(B) Temporal Numeric Predictors"))

grid.arrange(abundance_bioreg,size_bioreg,nrow=1,top="(C) Spp.-Related Numeric Predictors")
ggsave(filename = "../../results/Categorical_Outcome_Modeling_results/4.spp.rel_num_pred.png",plot =grid.arrange(abundance_bioreg,size_bioreg,nrow=1,top="(C) Spp.-Related Numeric Predictors"))
#grid.arrange(latitude_bioreg,longitude_bioreg,season_chron_bioreg,year_bioreg,site_bioreg,size_bioreg,abundance_bioreg,nrow=3)
```

## Characterizing categorical data
```{r}
categ_data <- bioregion_counts_ordered %>% select_if(is.factor) 
categ_data <- categ_data %>% dplyr::select(-marine_site_name,-season_sequence,-marine_season_code)
names(categ_data)
```

```{r}
categ_data_plotting <- categ_data %>% dplyr::select(-method_code_IP_other,-group_code_UCSC_other)

groupcode_bioreg <- categ_data_plotting %>% ggplot(aes(x = bioregion, y=group_code, col=bioregion)) + geom_jitter(size=4,alpha=0.15,width=0.4,height=0.25) + ylab("Surveying Group") + theme(axis.text.x = element_blank(),axis.title.x=element_blank(),legend.position = "none",axis.title.y=element_text(size=12),axis.text.y=element_text(size=12)) + scale_color_manual(values=bioreg_colours)
#groupcode_bioreg

sitecode_bioreg <- categ_data_plotting %>% ggplot(aes(x = bioregion, y=site_code, col=bioregion)) + geom_jitter(size=4,alpha=0.15,width=0.4,height=0.25) + ylab("Site") + theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(),axis.text.x = element_blank(),axis.title.x=element_blank(),axis.text.y = element_blank(),legend.position = "none",axis.title.y=element_text(size=12))+ scale_color_manual(values=bioreg_colours)
#sitecode_bioreg

season_bioreg <- categ_data_plotting %>% ggplot(aes(x = bioregion, y=season_name, col=bioregion)) + geom_jitter(size=4,alpha=0.15,width=0.4,height=0.25) + ylab("Season") + theme(axis.text.x = element_blank(),axis.title.x=element_blank(),legend.position = "none",axis.title.y=element_text(size=12),axis.text.y=element_text(size=12))+ scale_color_manual(values=bioreg_colours)
#season_bioreg

method_bioreg <- categ_data_plotting %>% ggplot(aes(x = bioregion, y=method_code, col=bioregion)) + geom_jitter(size=4,alpha=0.15,width=0.4,height=0.25) + ylab("Sampling Method") + theme(axis.text.x = element_blank(),axis.title.x=element_blank(),legend.position = "none",axis.title.y=element_text(size=12),axis.text.y=element_text(size=12))+ scale_color_manual(values=bioreg_colours)
#method_bioreg

species_bioreg <- categ_data_plotting %>% ggplot(aes(x = bioregion, y=species_code, col=bioregion)) + geom_jitter(size=4,alpha=0.15,width=0.4,height=0.25) + ylab("Species") + theme(axis.text.x = element_blank(),axis.title.x=element_blank(),legend.position = "none",axis.title.y=element_text(size=12),axis.text.y=element_text(size=12))+ scale_color_manual(values=bioreg_colours)
#species_bioreg

mpareg_bioreg <- categ_data_plotting %>% ggplot(aes(x = bioregion, y=mpa_region, col=bioregion)) + geom_jitter(size=4,alpha=0.15,width=0.4,height=0.25) + ylab("MPA Region") + theme(axis.text.x = element_blank(),axis.title.x=element_blank(),legend.position = "none",axis.title.y=element_text(size=12),axis.text.y=element_text(size=12))+ scale_color_manual(values=bioreg_colours)
#mpareg_bioreg

georegion_bioreg <- categ_data_plotting %>% ggplot(aes(x = bioregion, y=georegion, col=bioregion)) + geom_jitter(size=4,alpha=0.15,width=0.4,height=0.25) + ylab("Georegion") + theme(axis.text.x = element_blank(),axis.title.x=element_blank(),legend.position = "none",axis.title.y=element_text(size=12),axis.text.y=element_text(size=12))+ scale_color_manual(values=bioreg_colours)
#georegion_bioreg

island_bioreg <- categ_data_plotting %>% ggplot(aes(x = bioregion, y=island, col=bioregion)) + geom_jitter(size=4,alpha=0.15,width=0.4,height=0.25) + ylab("Island Location?") + theme(axis.text.x = element_blank(),axis.title.x=element_blank(),legend.position = "none",axis.title.y=element_text(size=12),axis.text.y=element_text(size=12))+ scale_color_manual(values=bioreg_colours)
#island_bioreg

state_bioreg <- categ_data_plotting %>% ggplot(aes(x = bioregion, y=state, col=bioregion)) + geom_jitter(size=4,alpha=0.15,width=0.4,height=0.25) + ylab("State") + theme(axis.text.x = element_blank(),axis.title.x=element_blank(),legend.position = "none",axis.title.y=element_text(size=12),axis.text.y=element_text(size=12))+ scale_color_manual(values=bioreg_colours)
#state_bioreg
```

```{r}
grid.arrange(groupcode_bioreg,method_bioreg,species_bioreg,nrow=3,top="(A) Sample Info Categorical Predictors")
ggsave(filename = "../../results/Categorical_Outcome_Modeling_results/5.sampleinfo_cat_pred.png",plot =grid.arrange(groupcode_bioreg,method_bioreg,species_bioreg,nrow=3,top="(A) Sample Info Categorical Predictors"))

grid.arrange(state_bioreg,georegion_bioreg,sitecode_bioreg,nrow=3,top="(B) Spatial Categorical Predictors")
ggsave(filename = "../../results/Categorical_Outcome_Modeling_results/6.spatial_cat_pred.png",plot =grid.arrange(state_bioreg,georegion_bioreg,sitecode_bioreg,nrow=3,top="(B) Spatial Categorical Predictors"))

grid.arrange(season_bioreg,mpareg_bioreg,island_bioreg,nrow=3,top="(C) Ecological Categorical Predictors")
ggsave(filename = "../../results/Categorical_Outcome_Modeling_results/7.eco_cat_pred.png",plot =grid.arrange(season_bioreg,mpareg_bioreg,island_bioreg,nrow=3,top="(C) Ecological Categorical Predictors"))

#grid.arrange(groupcode_bioreg,sitecode_bioreg,season_bioreg,method_bioreg,species_bioreg,mpareg_bioreg,georegion_bioreg,island_bioreg,state_bioreg)

```

## Modeling

Make sure Bioregion is first
```{r}
#names(clean_data) # bioregion is 19, 23 total, get rid of 3 and 14
clean_data_final <- clean_data[c(19,1,2,4,5,6,7,8,9,10,11,12,13,15,16,17,18,20,21,22,23)]
names(clean_data_final) # double checking
```


Data splitting
```{r}
#write code that splits data into 70/30 train/test
#call the 2 parts data_train and data_test
library(caret)
set.seed(123)
trainset_treefit <- caret::createDataPartition(y = clean_data_final$bioregion, p = 0.7, list = FALSE)
data_train_treefit = clean_data_final[trainset_treefit,] #extract observations/rows for training, assign to new variable
data_test_treefit = clean_data_final[-trainset_treefit,] #do the same for the test set
```

Model Fitting
Null Model
```{r}
library("mlr")
null_accuracy_treefit <- measureACC("SanFran_2_GovtPt", clean_data_final$bioregion)
null_accuracy_treefit
```

Single predictor models
```{r}
#There is probably a nicer tidyverse way of doing this. I just couldn't think of it, so did it this way.
set.seed(1111) #makes each code block reproducible
outcomename = "bioregion"
fitControl <- trainControl(method="repeatedcv",number=5,repeats=5) #setting CV method for caret
Npred <- ncol(data_train_treefit)-1 # number of predictors
resultmat <- data.frame(Variable = names(data_train_treefit)[-1], Accuracy = rep(0,Npred)) #store performance for each variable
for (n in 2:ncol(data_train_treefit)) #loop over each predictor. For this to work, outcome must be in 1st column
{
  fit1 <- caret::train( as.formula(paste(outcomename, "~",names(data_train_treefit)[n])), data = data_train_treefit, method = "rpart", trControl = fitControl, na.action = na.pass, tuneLength = 10) 
resultmat[n-1,2]= max(fit1$results$Accuracy)  
}
print(resultmat)
```

```{r}
null_accuracy_treefit <- 0.426
library(knitr)
library(kableExtra)
Variable <- c("size_bin","total","marine_common_year","species_code","island","method_code_IP_other","method_code","group_code_UCSC_other","state","marine_season_code","group_code","season_name","season_sequence","marine_common_season","site_code","mpa_region","georegion","latitude", "longitude","marine_sort_order")
Accuracy <- c(0.43,0.44,0.44,0.46,0.49,0.51,0.51,0.60,0.61,0.62,0.69,0.70,0.70,0.70,0.80,0.90,0.98,1.00,1.00,1.00)
Singlepred_df <- data.frame(Variable,Accuracy)
Singlepred_df
Singlepred_df_ordered <- Singlepred_df %>%
  mutate(Variable = factor(Variable, levels = c("size_bin","total","marine_common_year","species_code","island","method_code_IP_other","method_code","group_code_UCSC_other","state","marine_season_code","group_code","season_name","season_sequence","marine_common_season","site_code","mpa_region","georegion","latitude", "longitude","marine_sort_order"))) %>%
  arrange(Variable)

# vertical line conditioning
lvls <- levels(Singlepred_df_ordered$Variable)
vline.level <- 'site_code' # you want to draw line here, right before 18

#geom_vline(aes(xintercept = myLoc))
# plotting
Single_Predictor_Accuracy <- Singlepred_df_ordered %>% ggplot(aes(x = Variable, y=Accuracy, label =Accuracy)) + geom_hline(yintercept=null_accuracy_treefit,color='red', size=2,linetype="dashed") + ylim(0.35,1) + geom_text(stat='identity',color="black", size=5,fill="lightgrey",angle=90) + theme(title = element_text(size=12), axis.title.y = element_text(size=14),axis.title.x = element_blank(),axis.text.y = element_text(size=12), axis.text.x = element_text(size=8,angle=40,hjust=1))

Single_Predictor_Accuracy
ggsave(filename = "../../results/Categorical_Outcome_Modeling_results/8.single_predictor_accuracy.png",plot = Single_Predictor_Accuracy, width = 6, height = 4)
```


### So a lot of these have very strong (and in some cases, perfect, aka 100%) correlation with `bioregion`, and for very obvious reasons. Therefore, I'm going to remove variables in 2 ways: one will be more conservative (aka I'll be removing those with above a 90% accuracy- calling it `data_subset_A`) and one will be less conservative (aka I'll be removing those with above a 70% accuracy- calling it `data_subset_B`)

So lets do that now.
# Preparing Data Subset A
```{r}
data_subsetA <- clean_data_final %>% dplyr::select(-marine_sort_order, -latitude, -longitude, -mpa_region, -georegion)
```

# Data Splitting: Data Subset A
```{r}
#write code that splits data into 70/30 train/test
#call the 2 parts data_train and data_test
library(caret)
set.seed(123)
trainset_subsetA <- caret::createDataPartition(y = data_subsetA$bioregion, p = 0.7, list = FALSE)
data_train_subsetA = data_subsetA[trainset_subsetA,] #extract observations/rows for training, assign to new variable
data_test_subsetA = data_subsetA[-trainset_subsetA,] #do the same for the test set
```

Model Fitting
Null Model- Data Subset A
```{r}
library("mlr")
null_accuracy_subsetA <- measureACC("SanFran_2_GovtPt", data_subsetA$bioregion)
null_accuracy_subsetA
```


Single predictor models- Data Subset A
```{r}
#There is probably a nicer tidyverse way of doing this. I just couldn't think of it, so did it this way.
set.seed(1111) #makes each code block reproducible
outcomename = "bioregion"
fitControl <- trainControl(method="repeatedcv",number=5,repeats=5) #setting CV method for caret
Npred <- ncol(data_train_subsetA)-1 # number of predictors
resultmat <- data.frame(Variable = names(data_train_subsetA)[-1], Accuracy = rep(0,Npred)) #store performance for each variable
for (n in 2:ncol(data_train_subsetA)) #loop over each predictor. For this to work, outcome must be in 1st column
{
  fit1_subsetA <- caret::train(as.formula(paste(outcomename, "~",names(data_train_subsetA)[n])), data = data_train_subsetA, method = "rpart", trControl = fitControl, na.action = na.pass, tuneLength = 10) 
resultmat[n-1,2]= max(fit1_subsetA$results$Accuracy)  
}
print(resultmat)
```

Full model- Data Subset A
```{r}
set.seed(1111) #makes each code block reproducible
fitControl <- trainControl(method="repeatedcv",number=5,repeats=5) 
fit1_subsetA = caret::train(bioregion  ~ ., data=data_train_subsetA, method="rpart",  trControl = fitControl, na.action = na.pass, tuneLength = 10) 
print(fit1_subsetA$results)
```

```{r}
library(rpart.plot)
prp(fit1_subsetA$finalModel, extra = 1, type = 1)
```

# Preparing Data Subset B
```{r}
data_subsetB <- clean_data_final %>% dplyr::select(-marine_sort_order, -latitude, -longitude, -mpa_region, -georegion, -site_code, -marine_common_season)
```

# Data Splitting: Data Subset B
```{r}
#write code that splits data into 70/30 train/test
#call the 2 parts data_train and data_test
library(caret)
set.seed(123)
trainset_subsetB <- caret::createDataPartition(y = data_subsetB$bioregion, p = 0.7, list = FALSE)
data_train_subsetB = data_subsetB[trainset_subsetB,] #extract observations/rows for training, assign to new variable
data_test_subsetB = data_subsetB[-trainset_subsetB,] #do the same for the test set
```

Null Model- Data Subset B
```{r}
library("mlr")
null_accuracy_train_subsetB <- measureACC("SanFran_2_GovtPt", data_train_subsetB$bioregion)
null_accuracy_train_subsetB
```

Single predictor models- Data Subset B
```{r}
#There is probably a nicer tidyverse way of doing this. I just couldn't think of it, so did it this way.
set.seed(1111) #makes each code block reproducible
outcomename = "bioregion"
fitControl <- trainControl(method="repeatedcv",number=5,repeats=5) #setting CV method for caret
Npred <- ncol(data_train_subsetB)-1 # number of predictors
resultmat <- data.frame(Variable = names(data_train_subsetB)[-1], Accuracy = rep(0,Npred)) #store performance for each variable
for (n in 2:ncol(data_train_subsetB)) #loop over each predictor. For this to work, outcome must be in 1st column
{
  fit1_subsetB <- caret::train(as.formula(paste(outcomename, "~",names(data_train_subsetB)[n])), data = data_train_subsetB, method = "rpart", trControl = fitControl, na.action = na.pass, tuneLength = 10) 
resultmat[n-1,2]= max(fit1_subsetB$results$Accuracy)  
}
print(resultmat)
```


Full model- Data Subset B
Now let’s fit a full logistic model with all predictors.

```{r}
set.seed(1111) #makes each code block reproducible
fitControl <- trainControl(method="repeatedcv",number=5,repeats=5) 
fit1_subsetB = caret::train(bioregion  ~ ., data=data_train_subsetB, method="rpart",  trControl = fitControl, na.action = na.pass, tuneLength = 10) 
print(fit1_subsetB$results)
```

```{r}
library(rpart.plot)
prp(fit1_subsetB$finalModel, extra = 1, type = 1)
```


I'm going to continue on with just the Subset_B

Random forest
```{r}
set.seed(1111) #makes each code block reproducible
tuning_grid <- expand.grid( .mtry = seq(1,7,by=1), .splitrule = "gini", .min.node.size = seq(2,8,by=1) )
fit2 = caret::train(bioregion ~ ., data=data_train_subsetB, method="ranger", trControl = fitControl, tuneGrid = tuning_grid, na.action = na.pass) 
```

```{r}
plot(fit2)
```

Boosted tree ensemble
```{r}
library(gbm)
gbmGrid <- expand.grid(interaction.depth = seq(1, 7, by = 2), n.trees = 10, shrinkage = c(0.1, 0.01), n.minobsinnode = c(2,4,6))
fit3 = caret::train(bioregion ~ ., data=data_train_subsetB, method="gbm", trControl = fitControl, verbose=FALSE, tuneGrid = gbmGrid) 
plot(fit3)
```

Random forest with pre-processed predictors
```{r}
# copy the random forest code from above. Add a statement to the train() function that centers and scales predictors.
# save the result as fit4. 
set.seed(1111) #makes each code block reproducible
tuning_grid <- expand.grid( .mtry = seq(1,7,by=1), .splitrule = "gini", .min.node.size = seq(2,8,by=1) )
fit4 = caret::train(bioregion ~ ., preProcess = c("center", "scale"), data=data_train_subsetB, method="ranger",  trControl = fitControl, tuneGrid = tuning_grid, na.action = na.pass) 
plot(fit4)
```

Discriminant analysis
```{r}
#write code that trains a pda model, use tuneLength 20. Save as fit5 and plot.
set.seed(1111) #makes each code block reproducible
tuning_grid <- expand.grid(lambda = seq(0,1,by=0.05))
fit5 = caret::train(bioregion ~ ., data=data_train_subsetB, method="pda",  trControl = fitControl, tuneGrid = tuning_grid, na.action = na.pass, tuneLength = 20) 
#plot model results.
plot(fit5)
```

Comparing model performance
```{r randomforest-3, echo=TRUE}
resamps <- resamples(list(tree = fit1,
                          RF1 = fit2,
                          GBM = fit3,
                          RF2 = fit4, 
                          PDA = fit5))
bwplot(resamps)
```

The column labeled “Accuracy” is the overall agreement rate averaged over cross-validation iterations. The agreement standard deviation is also calculated from the cross-validation results. The column “Kappa” is Cohen’s (unweighted) Kappa statistic averaged across the resampling results.
```{r randomforest-3, echo=TRUE}
resamps_no_tree <- resamples(list(RF1 = fit2,
                          GBM = fit3,
                          RF2 = fit4, 
                          PDA = fit5))
bwplot(resamps_no_tree)
```

This suggests that while they are all pretty close, it seems like **GBM** (`fit3`) may be the best

# Evaluating the final model (boosted tree ensemble)

Model uncertainty in the predictions is shown in the previous plot.

For categorical outcomes, we can't plot residuals. But we can look at the final "2x2" (in this case, a 4x4) table (the confusion matrix) and compare true versus predicted outcomes and see if it shows any pattern.

```{r}
library('tidyr')
library('dplyr')
library('forcats')
library('ggplot2')
library('knitr')
library('caret')
#library('doParallel')
library('rpart')
library('rpart.plot')
library('mda')
library('ranger')
library('e1071')
```



```{r}
#Write code to get model predictions for the outcome on the training data..
predicted <- predict(fit3, data_train_subsetB)
confusion(data_train_subsetB$bioregion, predicted) #generates confusion matrix
# generating table with all results, with TRUE/FALSE accuracy column to compute ACC
train_data_results <- tibble("Actual" = data_train_subsetB$bioregion, "Predicted" = predicted)
train_accuracy <- measureACC(train_data_results$Predicted, train_data_results$Actual)
#use predicted and actual outcomes, make a table and compute accuracy.
```
```{r}
library(knitr)
#install.packages("kableExtra")
library(kableExtra)
labels <- c("Predicted","AK_BrtClm","Salish_WA","OlyCstWA_SF","SF_GovtPt","Chnl_Isl_S","GovtPt_Mexico")
AK_2_BritColumb_col <- c("AK_BrtClm",257,0,0,0,0,0)
SalishSea_WA_col <- c("Salish_WA",0,457,0,0,0,0)
OlyCstWA_2_SanFran_col <- c("OlyCstWA_SF",0,0,2560,25,0,1)
SanFran_2_GovtPt <- c("SF_GovtPt",0,0,337,3895,0,0)
ChannelIsl_South_col <- c("Chnl_Isl_S",0,0,0,0,25,0)
GovtPt_2_Mexico_col <- c("GovtPt_Mexico",0,0,0,6,0,1656)
contingency_table <- data.frame(labels,AK_2_BritColumb_col,SalishSea_WA_col,OlyCstWA_2_SanFran_col,SanFran_2_GovtPt,ChannelIsl_South_col,GovtPt_2_Mexico_col)
colnames(contingency_table) <- c("","Actual","","","","","")
#Multipred_df$RMSE <- as.(Multipred_df$RMSE)
contingency_table
kable(contingency_table) %>%
  kable_styling(full_width = F)

#ggsave(filename = "../../results/Categorical_Outcome_Modeling_results/12.PredvsActual.png",plot = kable(contingency_table), width = 5, height = 4)
```

```{r}
null_accuracy_test_subsetB <- measureACC("SanFran_2_GovtPt", data_test_subsetB$bioregion)
null_accuracy_test_subsetB
```


```{r predict}
#copy and paste the code from above, but now do it for the test set.
#Write code to get model predictions for the outcome on the training data..
predicted_final <- predict(fit3, data_test_subsetB)
confusion(data_test_subsetB$bioregion, predicted_final) #generates confusion matrix
# generating table with all results, with TRUE/FALSE accuracy column to compute ACC
test_data_results <- tibble("Actual" = data_test_subsetB$bioregion, "Predicted" = predicted_final)
test_accuracy <- measureACC(test_data_results$Predicted, test_data_results$Actual)
#use predicted and actual outcomes, make a table and compute accuracy.
```

```{r}
library(knitr)
#install.packages("kableExtra")
library(kableExtra)
labels <- c("Predicted","AK_BrtClm","Salish_WA","OlyCstWA_SF","SF_GovtPt","Chnl_Isl_S","GovtPt_Mexico")
AK_2_BritColumb_col <- c("AK_BrtClm",109,0,0,0,0,0)
SalishSea_WA_col <- c("Salish_WA",0,195,0,0,0,0)
OlyCstWA_2_SanFran_col <- c("OlyCstWA_SF",0,0,1096,14,0,3)
SanFran_2_GovtPt <- c("SF_GovtPt",0,0,145,1668,0,0)
ChannelIsl_South_col <- c("Chnl_Isl_S",0,0,0,0,10,0)
GovtPt_2_Mexico_col <- c("GovtPt_Mexico",0,0,0,0,0,706)


contingency_table2 <- data.frame(labels,AK_2_BritColumb_col,SalishSea_WA_col,OlyCstWA_2_SanFran_col,SanFran_2_GovtPt,ChannelIsl_South_col,GovtPt_2_Mexico_col)
colnames(contingency_table) <- c("","Actual","","","","","")
contingency_table2
kable(contingency_table) %>%
  kable_styling(full_width = F)
```


```{r}
null_accuracy_test_subsetB<- round(null_accuracy_test_subsetB,4)
null_accuracy_train_subsetB<- round(null_accuracy_train_subsetB,4)
train_accuracy<- round(train_accuracy,4)
test_accuracy <- round(test_accuracy,4)

Data_cat <- c("Null_train","GBMmodel_train","Null_test","GBMmodel_test")
accuracy_cat <- c(null_accuracy_train_subsetB,train_accuracy,null_accuracy_test_subsetB,test_accuracy)
Final_Results_cat <- data.frame(Data_cat,accuracy_cat)
Final_Results_cat

Final_Results_cat_ordered <- Final_Results_cat %>%
  mutate(Data_cat = factor(Data_cat, levels = c("Null_train","GBMmodel_train","Null_test","GBMmodel_test"))) %>%
  arrange(Data_cat) 

Final_Results_cat_ordered_plot <- Final_Results_cat_ordered %>% ggplot(aes(x = Data_cat, y=accuracy_cat, label=accuracy_cat)) +geom_label(stat='identity',fill=RMSE_colors, size=9, face="bold") + ylab("Accuracy (%)") + ylim(0.3,1.0) + 
  theme(title = element_text(size=12), axis.title.y = element_text(size=16),axis.title.x = element_blank(),axis.text.y = element_text(size=12), axis.text.x = element_text(size=12))

Final_Results_cat_ordered_plot

ggsave(filename = "../../results/Categorical_Outcome_Modeling_results/14.final_results_cat.png",plot = Final_Results_cat_ordered_plot, width = 5, height = 4)
```


Obviously accuracy went down, but only by ~1%, and its still very high. 























