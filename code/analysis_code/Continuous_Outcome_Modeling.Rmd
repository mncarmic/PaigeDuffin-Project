---
title: "Continuous_Variable_Analysis"
author: "Paige Duffin"
date: "11/7/2019"
output: html_document
---

# Exploratory Analysis {.tabset}

## Preparing Workspace

Load necessary packages
```{r}
library(caret) # Classification and Regression Training
library(corrplot)
library(dplyr) # A Grammar of Data Manipulations
library(forcats) # Tools for Working with Categorical Variables (Factors)
library(gdata) # Various R Programming Tools for Data Manipulation
library(ggplot2) # Create Elegant Data Visualizations Using the Grammar of Graphics
library(ggrepel) # Automatically Position Non-Overlapping Text Labels with ‘ggplot2’
library(ggridges) # Ridgeline Plots in ‘ggplot2’
library(ggthemes) # Extra Themes, Scales, and Geoms for ‘ggplot2’
library(gmodels) # Various R Programming Tools for Model Fitting
library(grid) # The Grid Graphics Package
library(gridExtra)
library(knitr) # A General-Purpose Package for Dynamic Report Generation in R
library(lmtest) # Testing Linear Regression Models
library(plyr) # Tools for Splitting, Applying and Combining Data
library(purrr) # Functional Programming Tools
library(readr) # Read Rectangular Text Data
library(rpart)
library(rattle)
library(scales) # Scale Functions for Visualization
library(shiny) # Web Application Framework for R
library(skimr) # Compact and Flexible Summaries of Data
library(stringr) # Simple, Consistent Wrappers for Common String Operations
library(tibble) # Simple Data Frames
library(tidyr) # Easily Tidy Data with ‘spread()’ and ‘gather()’ Functions
library(tidyverse) # Install and Load ‘Tidyverse’ Packages
library(usmap)
library(rworldmap)
library(ggmap)
library(maps)
library(mapdata)
library(cowplot)
library("googleway")
library("ggspatial") 
library("rnaturalearth") 
library("rnaturalearthdata")
theme_set(theme_bw())
library("sf")
library(gridExtra)

world <- ne_countries(scale = "medium", returnclass = "sf") #for mapping
```

Load cleaned data
```{r}
#clean_data <- readRDS("./data/processed_data/processeddata.rds")
clean_data <- readRDS("../../data/processed_data/processeddata.rds")
skim(clean_data)
```

temp_and_salt <- ggplot(WQ_clean_data, aes(x = salinity, y = water_temp, color = island_side)) + geom_jitter()


Outcome of interest is `total`, but really just for Pisaster. 
```{r}
P.ochra_clean_data <- filter(clean_data, clean_data$species_code == "P.ochraceus")
#names(P.ochra_clean_data)
P.ochra_numer_data <- P.ochra_clean_data %>% dplyr::select(total, marine_common_season, marine_common_year, marine_sort_order, season_sequence, size_bin, size_sort_order, latitude, longitude)

P.ochra_numer_data <- P.ochra_numer_data %>% mutate(season_year = marine_common_season) %>% dplyr::select(-marine_common_season)

P.ochra_numer_data <- P.ochra_numer_data %>% mutate(year = marine_common_year) %>% dplyr::select(-marine_common_year)

P.ochra_numer_data <- P.ochra_numer_data %>% mutate(season_num = season_sequence) %>% dplyr::select(-season_sequence)

P.ochra_numer_data <- P.ochra_numer_data %>% mutate(size_sort = size_sort_order) %>% dplyr::select(-size_sort_order)

P.ochra_numer_data <- P.ochra_numer_data %>% mutate(order_site = marine_sort_order) %>% dplyr::select(-marine_sort_order)
```

```{r}
visdat::vis_dat(P.ochra_numer_data)
```

```{r}
p1 <- P.ochra_numer_data %>% select_if(is.numeric) %>% gather(-total, key = "var", value = "value") %>% 
            ggplot() + geom_point(aes(x = value, y=total)) +
            facet_wrap(~ var, scales = "free") + theme_bw()
print(p1)
```

```{r}
p1log <- P.ochra_numer_data %>% select_if(is.numeric) %>% gather(-total, key = "var", value = "value") %>% 
            ggplot() + geom_point(aes(x = value, y=log(total)), alpha = 0.2) +
            facet_wrap(~ var, scales = "free") + theme_bw()
print(p1log)

ggsave(filename = "../../results/Continuous_Outcome_Modeling_results/count_vs_numerical.png",plot = p1log, width = 5, height = 4)
```

```{r}
P.ochra_numer_data_corr <- P.ochra_numer_data %>% select_if(is.numeric) %>% cor() 
P.ochra_numer_data_corr <- corrplot::corrplot(P.ochra_numer_data_corr)
```

Okay, so a few of these are highly correlated, and for good reason. The only one I can really think to justify getting rid of one of the two correlated variables for is the `size_sort`/`size_bin`. `size_sort` is as informative as `size_bin`, and more, so I'll get rid of `size_bin`
```{r}
P.ochra_numer_data <- P.ochra_numer_data %>% dplyr::select(-size_bin)
```

```{r}
P.ochra_categ_data <- P.ochra_clean_data %>% select_if(is.factor)
P.ochra_categ_data$total <- P.ochra_clean_data$total
P.ochra_categ_data <- P.ochra_categ_data %>% dplyr::select(-species_code)
p2 <- P.ochra_categ_data %>% gather(-total, -marine_season_code, key = "var", value = "value") %>% ggplot() + geom_violin(aes(x = value, y=total)) + geom_point(aes(x = value, y=total)) + facet_wrap(~ var, scales = "free") + theme_bw()
print(p2)
```

```{r}
P.ochra_categ_data <- P.ochra_clean_data %>% select_if(is.factor)
P.ochra_categ_data$total <- P.ochra_clean_data$total
P.ochra_categ_data <- P.ochra_categ_data %>% dplyr::select(-species_code)
p2log <- P.ochra_categ_data %>% gather(-total, -marine_season_code, key = "var", value = "value") %>% ggplot() + geom_violin(aes(x = value, y=log(total), col=value)) + geom_point(aes(x = value, y=log(total), col=value)) + facet_wrap(~ var, scales = "free") + theme_bw() + theme(legend.position = "none")
print(p2log)

ggsave(filename = "../../results/Continuous_Outcome_Modeling_results/count_vs_categorical.png",plot = p2log, width = 5, height = 4)
```

```{r}
p2_mpa <- P.ochra_categ_data %>% ggplot() + geom_violin(aes(x = mpa_region, y=log(total))) + geom_point(aes(x = mpa_region, y=log(total))) + theme_bw()
print(p2_mpa)
```

## Model Fitting

### Data Splitting
```{r}
set.seed(123)
trainset <- caret::createDataPartition(y = P.ochra_numer_data$total, p = 0.7, list = FALSE)
data_train = P.ochra_numer_data[trainset,] #extract observations/rows for training, assign to new variable
data_test = P.ochra_numer_data[-trainset,] #do the same for the test set
```

### Null Model
```{r}
outcome = data_train$total
Nobs=nrow(data_train)
base_RMSE <- sqrt(sum((outcome-mean(outcome))^2)/Nobs)
print(sprintf('RMSE of baseline model is %f',base_RMSE))
```

### Single Predictor Models

```{r}
#There is probably a nicer tidyverse way of doing this. I just couldn't think of it, so did it this way.
set.seed(1111) #makes each code block reproducible
fitControl <- trainControl(method="repeatedcv",number=5,repeats=5) #setting CV method for caret
Npred <- ncol(data_train)-1 # number of predictors
resultmat <- data.frame(Variable = names(data_train)[-1], RMSE = rep(0,Npred)) #store values for RMSE for each variable
for (n in 2:ncol(data_train)) #loop over each predictor. For this to work, outcome must be in 1st column
{
  fit1 <- train( as.formula(paste("total ~",names(data_train)[n])) , data = data_train, method = "lm", trControl = fitControl) 
 resultmat[n-1,2]= fit1$results$RMSE  
}
print(resultmat)
```

### Multiple Predictor Models

```{r}
set.seed(1111) #makes each code block reproducible
fitControl <- trainControl(method="repeatedcv",number=5,repeats=5) 
fit2 <- train(total ~ ., data = data_train, method = "lm", trControl = fitControl) 
fit3 <- train(total ~ ., data = data_train, method = "knn", trControl = fitControl)
fit4 <- train(total ~ ., data = data_train, method = "earth", trControl = fitControl) 
print(sprintf('RMSE of lm/knn/mars model %f/%f/%f', fit2$results$RMSE, min(fit3$results$RMSE), min(fit4$results$RMSE) ))
```

### Multi-predictor models with pre-processing

```{r}
nzv <- caret::nearZeroVar(data_train, saveMetrics= TRUE)
print(nzv)
```

None of my predictors have a near-zero variance so I'm not going to remove anthing at this step. 

#### Center and Scale
Next, we noticed during our exploratory analysis that it might be useful to center and scale predictors. So let’s do that now. With caret, one can do that by providing the preProc setting inside the train function. Set it to center and scale the data, then run the 3 models from above again.
```{r}
#write code that repeats the multi-predictor fits from above, but this time applies centering and scaling of variables.
#look at the RMSE for the new fits
fitControl <- trainControl(method="repeatedcv",number=5,repeats=5) 
fit2a <- train(total ~ ., data = data_train, method = "lm", trControl = fitControl, preProc = c("center","scale")) 
fit3a <- train(total ~ ., data = data_train, method = "knn", trControl = fitControl, preProc = c("center","scale"))
fit4a <- train(total ~ ., data = data_train, method = "earth", trControl = fitControl, preProc = c("center","scale")) 
print(sprintf('RMSE of lm/knn/mars model %f/%f/%f', fit2a$results$RMSE, min(fit3a$results$RMSE), min(fit4a$results$RMSE) ))
```

### Model Uncertainty
```{r}
#Use the `resamples` function in caret to extract uncertainty from the 3 models fit to the data  that doesn't have predictor pre-processing, then plot it
resamps <- caret::resamples(list(LM = fit2, KNN = fit3, MARS = fit4))
bwplot(resamps, layout = c(3, 1))
```


### Residual plots
```{r}
#Write code to get model predictions for the outcome on the training data, and plot it as function of actual outcome values.
#also compute residuals (the difference between prediction and actual outcome) and plot that
pred <- predict(fit3,data_train)
outcome <- data_train$total
resid <- outcome - pred
plot(outcome,pred,xlim = c(0,270),ylim=c(0,250))
```

```{r}
plot(resid)
```

## Final model evaluation
```{r}
#Write code that computes model predictions and for test data, then compute SSR and RMSE.
pred <- predict(fit3,data_test)
outcome <- data_test$total
SSR <- sum( (outcome - pred)^2 )
RMSE = sqrt(SSR/length(outcome))
print(RMSE)
```

Since we have a different number of observations, the result isn’t expected to be quite the same as for the training data (despite dividing by sample size to account for that). But it’s fairly close, and surprisingly not actually worse. So the KNN model seems to be reasonable at predicting. Now if its performance is ‘good enough’ is a scientific question.







